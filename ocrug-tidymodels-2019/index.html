<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Working with tidymodels</title>
    <meta charset="utf-8" />
    <meta name="author" content="Emil Hvitfeldt" />
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link rel="stylesheet" href="theme.css" type="text/css" />
    <link rel="stylesheet" href="colors.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, title-slide

# Working with tidymodels
## OCRUG meetup
### Emil Hvitfeldt
### 2019-1-29

---




`tidymodels` is a "meta-package" for modeling and statistical analysis that share the underlying design philosophy, grammar, and data structures of the tidyverse.

.left-column[
![](https://raw.githubusercontent.com/rstudio/hex-stickers/master/PNG/tidymodels.png)
]

.right-column[

```r
library(tidymodels)
```


```r
## ✔ broom     0.5.1          ✔ purrr     0.3.0     
## ✔ dials     0.0.2          ✔ recipes   0.1.4     
## ✔ dplyr     0.7.8          ✔ rsample   0.0.4     
## ✔ ggplot2   3.1.0          ✔ tibble    2.0.1     
## ✔ infer     0.4.0          ✔ yardstick 0.0.2     
## ✔ parsnip   0.0.1.9000
```
]

---

# The packages

.pull-left[
- broom
- dials
- dplyr
- ggplot2
- infer
- parsnip
]

.pull-right[
- purrr
- recipes
- rsample
- tibble
- yardstick
]

---

# The packages (tidyverse)

.pull-left[
- broom
- dials
- **dplyr**
- **ggplot2**
- infer
- parsnip
]

.pull-right[
- **purrr**
- recipes
- rsample
- **tibble**
- yardstick
]

---

# The packages (tidyverse)

.pull-left[
- broom
- dials
- **.light[dplyr]**
- **.light[ggplot2]**
- infer
- parsnip
]

.pull-right[
- **.light[purrr]**
- recipes
- rsample
- **.light[tibble]**
- yardstick
]

---

# The packages

.pull-left[
- **.light[broom]**
- **.light[dials]**
- **.light[dplyr]**
- **.light[ggplot2]**
-  **.light[infer]**
- **parsnip**
]

.pull-right[
- **.light[purrr]**
- **recipes**
- **rsample**
- **.light[tibble]**
- **yardstick**
]

---

# ⚠️ Disclaimer ⚠️

This talk is not designed to give opinions with respect to modeling best practices.

This talk is designed to showcase what packages are available and what they can do.

---

# Consider 32 cars from 1973-74


```r
head(mtcars)
```

```
##                    mpg cyl disp  hp drat    wt  qsec vs am gear carb
## Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4
## Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4
## Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1
## Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1
## Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2
## Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1
```

---


```r
model_glm &lt;- glm(am ~ disp + drat + qsec, data = mtcars, 
                 family = "binomial")
```

--


```r
predict(model_glm)
```

```
##           Mazda RX4       Mazda RX4 Wag          Datsun 710      Hornet 4 Drive 
##           105.97448            69.85214            27.10173          -276.59440 
##   Hornet Sportabout             Valiant          Duster 360           Merc 240D 
##          -240.20025          -313.42683          -158.99087          -123.81721 
##            Merc 230            Merc 280           Merc 280C          Merc 450SE 
##          -284.08255           -20.37716           -59.07966          -167.78204 
##          Merc 450SL         Merc 450SLC  Cadillac Fleetwood Lincoln Continental 
##          -180.68287          -206.48454          -458.77204          -427.72554 
##   Chrysler Imperial            Fiat 128         Honda Civic      Toyota Corolla 
##          -357.75792            27.25037           164.39652            20.76278 
##       Toyota Corona    Dodge Challenger         AMC Javelin          Camaro Z28 
##           -90.84576          -211.90064          -189.27739           -74.78345 
##    Pontiac Firebird           Fiat X1-9       Porsche 914-2        Lotus Europa 
##          -297.35324            63.64819           184.39936           146.50220 
##      Ford Pantera L        Ferrari Dino       Maserati Bora          Volvo 142E 
##            24.28831           162.60217            21.69348            33.80864
```

---


```r
library(glmnet)
model_glmnet &lt;- glmnet(am ~ disp + drat + qsec, data = mtcars, 
                       family = "binomial")
```

--


```
## Loading required package: Matrix
```

```
## 
## Attaching package: 'Matrix'
```

```
## The following objects are masked from 'package:tidyr':
## 
##     expand, pack, unpack
```

```
## Loaded glmnet 3.0-2
```

```
## Error in drop(y): argument "y" is missing, with no default
```

--

&lt;br&gt;


```r
model_glmnet &lt;- glmnet(x = as.matrix(mtcars[, c("disp", "drat", "qsec")]),
                       y = mtcars[, "am"],
                       family = "binomial")
```

--

&lt;br&gt;


```r
model_glm &lt;- glm(x = as.matrix(mtcars[, c("disp", "drat", "qsec")]),
                 y = mtcars[, "am"],
                 family = "binomial")
```

--


```
## Error in environment(formula): argument "formula" is missing, with no default
```

---

# User-facing problems in modeling in R

- Data must be a matrix (except when it needs to be a data.frame)
- Must use formula or x/y (or both)
- Inconsistent naming of arguments (ntree in randomForest, num.trees in ranger)
- na.omit explicitly or silently
- May or may not accept factors

--

.center[![](https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/240/apple/155/tired-face_1f62b.png)]

---

# Syntax for Computing Predicted Class Probabilities

|Function     |Package      |Code                                       |
|:------------|:------------|:------------------------------------------|
|`lda`        |`MASS`       |`predict(obj)`                             |
|`glm`        |`stats`      |`predict(obj, type = "response")`          |
|`gbm`        |`gbm`        |`predict(obj, type = "response", n.trees)` |
|`mda`        |`mda`        |`predict(obj, type = "posterior")`         |
|`rpart`      |`rpart`      |`predict(obj, type = "prob")`              |
|`Weka`       |`RWeka`      |`predict(obj, type = "probability")`       |
|`logitboost` |`LogitBoost` |`predict(obj, type = "raw", nIter)`        |

blatantly stolen from Max Kuhn

---

![:scale 50%](https://raw.githubusercontent.com/rstudio/hex-stickers/master/PNG/parsnip.png)

---

The goals of `parsnip` is...  

- Decouple the *model classification* from the *computational engine*
- Separate the definition of a model from its evaluation
- Harmonize argument names
- Make consistent predictions (always tibbles with na.omit=FALSE)

---


```r
model_glm &lt;- glm(am ~ disp + drat + qsec, data = mtcars, 
                 family = "binomial")
```

---


```r
library(parsnip)
model_glm &lt;- logistic_reg(mode = "classification") %&gt;%
  set_engine("glm")

model_glm
```

```
## Logistic Regression Model Specification (classification)
## 
## Computational engine: glm
```

--


```r
fit_glm &lt;- model_glm %&gt;%
  fit(factor(am) ~ disp + drat + qsec, data = mtcars)
```

???
decision_tree(), linear_reg(), logistic_reg(), rand_forest(), svm_poly()

---


```r
library(parsnip)
model_glmnet &lt;- logistic_reg(mode = "classification") %&gt;%
  set_engine("glmnet")
model_glmnet
```

```
## Logistic Regression Model Specification (classification)
## 
## Computational engine: glmnet
```


```r
fit_glmnet &lt;- model_glmnet %&gt;%
  fit(factor(am) ~ disp + drat + qsec, data = mtcars)
```

---

### Using both formula and x/y

#### Formula

```r
fit_glm &lt;- model_glm %&gt;%
  fit(factor(am) ~ ., data = mtcars)
```

#### x/y

```r
fit_glm &lt;- model_glm %&gt;%
  fit_xy(x = as.matrix(mtcars[, c("disp", "drat", "qsec")]),
         y = factor(mtcars[, "am"]), 
         data = mtcars)
```

---

# Tidy prediction


```r
predict(fit_glm, mtcars)
```

```
## # A tibble: 32 x 1
##    .pred_class
##    &lt;fct&gt;      
##  1 1          
##  2 1          
##  3 1          
##  4 0          
##  5 0          
##  6 0          
##  7 0          
##  8 0          
##  9 0          
## 10 0          
## # … with 22 more rows
```

---

Consider now that we wanted to model a more advanded relation ship between variables


```r
fit_glm &lt;- model_glm %&gt;%
  fit(factor(am) ~ poly(mpg, 3) + pca(disp:wt)[1] + pca(disp:wt)[2] + pca(disp:wt)[3], 
      data = mtcars)
```

--

- Not all inline functions can be used with formulas
- Having to run some calculations many many times
- Connected to the model, calculations are not saved between models

Post by Max Kuhn about the bad sides of formula
https://rviews.rstudio.com/2017/03/01/the-r-formula-method-the-bad-parts/

---

![:scale 45%](https://raw.githubusercontent.com/rstudio/hex-stickers/master/PNG/recipes.png)

???

Preprocessing - statistics  
Feature engineering - Computer Science

---

### Preprocessing steps

Some of things you may need to deal with before you can start modeling

- Same unit (center and scale)
- Remove correlation (filter and PCA extraction)
- Missing data (imputation)
- Dummy varibles
- Zero Variance

---

### Same units


```r
library(recipes)
car_rec &lt;- recipe(mpg ~ ., mtcars) %&gt;%
  step_center(all_predictors()) %&gt;%
  step_scale(all_predictors())
```

### PCA


```r
library(recipes)
car_rec &lt;- recipe(mpg ~ ., mtcars) %&gt;%
  step_pca(all_predictors(), threshold = 0.8)
```

### Any combination of steps


```r
car_rec &lt;- recipe(mpg ~ ., mtcars) %&gt;%
  step_knnimpute(drat, wt, neighbors = 5) %&gt;%
  step_zv(all_predictors()) %&gt;%
  step_pca(all_predictors(), threshold = 0.8)
```

---


```r
library(recipes)
car_rec &lt;- recipe(mpg ~ ., mtcars) %&gt;%
  step_center(all_predictors()) %&gt;%
  step_scale(all_predictors())
```

--


```r
car_rec
```

```
## Data Recipe
## 
## Inputs:
## 
##       role #variables
##    outcome          1
##  predictor         10
## 
## Operations:
## 
## Centering for all_predictors
## Scaling for all_predictors
```

---


```r
library(recipes)
car_rec &lt;- recipe(mpg ~ ., mtcars) %&gt;%
  step_center(all_predictors()) %&gt;%
  step_scale(all_predictors())

car_preped &lt;- prep(car_rec, training = mtcars)
```

--


```r
bake(car_preped, new_data = mtcars)
```

--


```
## # A tibble: 32 x 11
##       cyl    disp     hp   drat       wt   qsec     vs     am   gear   carb
##     &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
##  1 -0.105 -0.571  -0.535  0.568 -0.610   -0.777 -0.868  1.19   0.424  0.735
##  2 -0.105 -0.571  -0.535  0.568 -0.350   -0.464 -0.868  1.19   0.424  0.735
##  3 -1.22  -0.990  -0.783  0.474 -0.917    0.426  1.12   1.19   0.424 -1.12 
##  4 -0.105  0.220  -0.535 -0.966 -0.00230  0.890  1.12  -0.814 -0.932 -1.12 
##  5  1.01   1.04    0.413 -0.835  0.228   -0.464 -0.868 -0.814 -0.932 -0.503
##  6 -0.105 -0.0462 -0.608 -1.56   0.248    1.33   1.12  -0.814 -0.932 -1.12 
##  7  1.01   1.04    1.43  -0.723  0.361   -1.12  -0.868 -0.814 -0.932  0.735
##  8 -1.22  -0.678  -1.24   0.175 -0.0278   1.20   1.12  -0.814  0.424 -0.503
##  9 -1.22  -0.726  -0.754  0.605 -0.0687   2.83   1.12  -0.814  0.424 -0.503
## 10 -0.105 -0.509  -0.345  0.605  0.228    0.253  1.12  -0.814  0.424  0.735
## # … with 22 more rows, and 1 more variable: mpg &lt;dbl&gt;
```

---


```r
library(recipes)
car_rec &lt;- recipe(mpg ~ ., mtcars) %&gt;%
  step_center(all_predictors()) %&gt;%
  step_scale(all_predictors())

car_preped &lt;- prep(car_rec, training = mtcars)
```


```r
juice(car_preped)
```

```
## # A tibble: 32 x 11
##       cyl    disp     hp   drat       wt   qsec     vs     am   gear   carb
##     &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
##  1 -0.105 -0.571  -0.535  0.568 -0.610   -0.777 -0.868  1.19   0.424  0.735
##  2 -0.105 -0.571  -0.535  0.568 -0.350   -0.464 -0.868  1.19   0.424  0.735
##  3 -1.22  -0.990  -0.783  0.474 -0.917    0.426  1.12   1.19   0.424 -1.12 
##  4 -0.105  0.220  -0.535 -0.966 -0.00230  0.890  1.12  -0.814 -0.932 -1.12 
##  5  1.01   1.04    0.413 -0.835  0.228   -0.464 -0.868 -0.814 -0.932 -0.503
##  6 -0.105 -0.0462 -0.608 -1.56   0.248    1.33   1.12  -0.814 -0.932 -1.12 
##  7  1.01   1.04    1.43  -0.723  0.361   -1.12  -0.868 -0.814 -0.932  0.735
##  8 -1.22  -0.678  -1.24   0.175 -0.0278   1.20   1.12  -0.814  0.424 -0.503
##  9 -1.22  -0.726  -0.754  0.605 -0.0687   2.83   1.12  -0.814  0.424 -0.503
## 10 -0.105 -0.509  -0.345  0.605  0.228    0.253  1.12  -0.814  0.424  0.735
## # … with 22 more rows, and 1 more variable: mpg &lt;dbl&gt;
```

---

&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
.huge[
.center[

```r
recipe -&gt; prepare -&gt; bake/juice

(define) -&gt; (estimate) -&gt; (apply)
```
]
]

---

## Types of data splitting

- Random
- By date
- By outcome
    - Classification: within class
    - regression: within quantile
    
---

## Training and Testing sets


```r
library(rsample)

car_preped &lt;- prep(car_rec, training = mtcars)
```

---

![:scale 45%](https://raw.githubusercontent.com/rstudio/hex-stickers/master/PNG/rsample.png)

---

## Training and Testing sets


```r
library(rsample)

set.seed(4595)

# These slides were almost finished and I didn't want to change the data in all the other slides
big_mtcars &lt;- rerun(10, mtcars) %&gt;%
  bind_rows()

data_split &lt;- initial_split(big_mtcars, strata = "mpg", p = 0.80)

# Training and test data
cars_train &lt;- training(data_split)
cars_test  &lt;- testing(data_split)

car_prep &lt;- prep(car_rec, training = cars_train)

# Preprocessed data
cars_train_p &lt;- juice(car_prep)
cars_test_p &lt;- bake(car_prep, new_data = cars_test)
```

---

![:scale 45%](https://raw.githubusercontent.com/rstudio/hex-stickers/master/PNG/yardstick.png)

---


```r
library(yardstick)
head(two_class_example)
```

```
##    truth      Class1       Class2 predicted
## 1 Class2 0.003589243 0.9964107574    Class2
## 2 Class1 0.678621054 0.3213789460    Class1
## 3 Class2 0.110893522 0.8891064779    Class2
## 4 Class1 0.735161703 0.2648382969    Class1
## 5 Class2 0.016239960 0.9837600397    Class2
## 6 Class1 0.999275071 0.0007249286    Class1
```

--


```r
metrics(two_class_example, truth = truth, estimate = predicted)
```

```
## # A tibble: 2 x 3
##   .metric  .estimator .estimate
##   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;
## 1 accuracy binary         0.838
## 2 kap      binary         0.675
```

---


```r
library(yardstick)
head(two_class_example)
```

```
##    truth      Class1       Class2 predicted
## 1 Class2 0.003589243 0.9964107574    Class2
## 2 Class1 0.678621054 0.3213789460    Class1
## 3 Class2 0.110893522 0.8891064779    Class2
## 4 Class1 0.735161703 0.2648382969    Class1
## 5 Class2 0.016239960 0.9837600397    Class2
## 6 Class1 0.999275071 0.0007249286    Class1
```


```r
accuracy(two_class_example, truth = truth, estimate = predicted)
```

```
## # A tibble: 1 x 3
##   .metric  .estimator .estimate
##   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;
## 1 accuracy binary         0.838
```

---


```r
library(yardstick)
head(two_class_example)
```

```
##    truth      Class1       Class2 predicted
## 1 Class2 0.003589243 0.9964107574    Class2
## 2 Class1 0.678621054 0.3213789460    Class1
## 3 Class2 0.110893522 0.8891064779    Class2
## 4 Class1 0.735161703 0.2648382969    Class1
## 5 Class2 0.016239960 0.9837600397    Class2
## 6 Class1 0.999275071 0.0007249286    Class1
```


```r
j_index(two_class_example, truth = truth, estimate = predicted)
```

```
## # A tibble: 1 x 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 j_index binary         0.673
```

And many more!!

---


```r
library(yardstick)
head(two_class_example)
```

```
##    truth      Class1       Class2 predicted
## 1 Class2 0.003589243 0.9964107574    Class2
## 2 Class1 0.678621054 0.3213789460    Class1
## 3 Class2 0.110893522 0.8891064779    Class2
## 4 Class1 0.735161703 0.2648382969    Class1
## 5 Class2 0.016239960 0.9837600397    Class2
## 6 Class1 0.999275071 0.0007249286    Class1
```


```r
conf_mat(two_class_example, truth = truth, estimate = predicted)
```

```
##           Truth
## Prediction Class1 Class2
##     Class1    227     50
##     Class2     31    192
```

---


```r
roc_curve(two_class_example, truth = truth, Class1) %&gt;%
  autoplot()
```

&lt;img src="index_files/figure-html/unnamed-chunk-42-1.png" width="700px" style="display: block; margin: auto;" /&gt;
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="macros.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  /* Replace <script> tags in slides area to make them executable
   *
   * Runs after post-processing of markdown source into slides and replaces only
   * <script>s on the last slide of continued slides using the .has-continuation
   * class added by xaringan. Finally, any <script>s in the slides area that
   * aren't executed are commented out.
   */
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container:not(.has-continuation) script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
  var scriptsNotExecuted = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container.has-continuation script'
  );
  if (!scriptsNotExecuted.length) return;
  for (var i = 0; i < scriptsNotExecuted.length; i++) {
    var comment = document.createComment(scriptsNotExecuted[i].outerHTML)
    scriptsNotExecuted[i].parentElement.replaceChild(comment, scriptsNotExecuted[i])
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
